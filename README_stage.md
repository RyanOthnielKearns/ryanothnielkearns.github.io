I'm a student at the [Oxford Internet Institute](https://www.oii.ox.ac.uk). With support from the [Cosmos Institute](https://cosmos-institute.org), I'm honored to be an inaugural Cosmos Fellow at the [Oxford Human-Centered AI Lab](https://www.oxford-aiethics.ox.ac.uk/news/launch-new-human-centered-ai-lab), housed within the [Institute for Ethics in AI](https://www.oxford-aiethics.ox.ac.uk), University of Oxford.

I study epistemic infrastructure. Broadly construed, these are the socio-technical systems through which we create, cultivate, maintain, and disseminate knowledge. Wikipedia, arXiv, and Reddit are epistemic infrastructure. They inform much of our worldview and our public discourse, and modern AI is critically dependent upon them.

What unites these systems is that they are complex, networked, dynamic, linguistic, and politicized stores of information. We can use mathematical techniques—data science, network science, NLP, modal logic, computational social choice—to understand them. Specifically, we can understand their failure modes—echo chambers, disinformation, unconscious bias—and try to mitigate them.

Previously, I studied [Philosophy](https://philosophy.stanford.edu) (BAH) and [Computer Science](https://www.cs.stanford.edu) (BS) at Stanford University. I wrote a [thesis](https://arxiv.org/abs/2303.08900) about trust—what it is, philosophically, and what is required for a philosophically defensible account of trust in explainable AI literature.

I also worked at [Monte Carlo Data](https://www.montecarlodata.com) as a Founding Data Scientist, did [NLP research](https://aclanthology.org/2022.findings-acl.317/) with [Stanford OVAL](https://oval.cs.stanford.edu), and wrote three chapters of the [Data Quality Fundamentals](https://www.oreilly.com/library/view/data-quality-fundamentals/9781098112035/) textbook with O'Reilly Media.

You can email me by bruteforcing this Caesar Cipher using the ASCII alphabet: ```ipXe%b\Xiej7f``%fo%XZ%lb```